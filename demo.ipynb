{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVTS Data Toolkit\n",
    "\n",
    "## Demo\n",
    "\n",
    "This demo is designed to give the user a quick tour over the software's funcionalities. Below is a list of all the things one could see in this demo:\n",
    " - Downloading a dataset of 2000 multivariate time series (mvts) instances.\n",
    " - Getting some basic statistics about your data.\n",
    " - Extracting a list of statistical features from the mvts instances.\n",
    " - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from data_retriever import DataRetriever  # for downloading data\n",
    "import CONSTANTS as CONST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Dataset\n",
    "In this demo we use an example dataset. In the following cells, it will be automatically downloaded. But in case something goes wrong, here is the direct link:\n",
    "https://bitbucket.org/gsudmlab/mvtsdata_toolkit/downloads/petdataset_01.zip\n",
    "\n",
    "Before we download it, let's take a quick look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL:\t\thttps://bitbucket.org/gsudmlab/mvtsdata_toolkit/downloads/petdataset_01.zip\n",
      "NAME:\t\tpetdataset_01.zip\n",
      "TYPE:\t\tapplication/zip\n",
      "SIZE:\t\t32M\n"
     ]
    }
   ],
   "source": [
    "dr = DataRetriever(1)\n",
    "print('URL:\\t\\t{}'.format(dr.dataset_url))\n",
    "print('NAME:\\t\\t{}'.format(dr.dataset_name))\n",
    "print('TYPE:\\t\\t{}'.format(dr.get_compression_type()))\n",
    "print('SIZE:\\t\\t{}'.format(dr.get_total_size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready to download? This may take a few seconds, depending on your internet bandwidth. Wait for the progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 2001/2001 [00:01<00:00, 1638.67it/s]\n"
     ]
    }
   ],
   "source": [
    "where_to = 'temp/'\n",
    "dr.retrieve(target_path = where_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Let's see how many files are available to us now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.get_total_number_of_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Configurations\n",
    "For tasks such as feature extraction (by `feature_extractor`) and data analysis (by `mvts_data_analysis` and `extracted_features_analysis`) a configuration file must be provided. We provide one inside this package, but you can create your own and place it anywhere you wish. Let's take a look at ours which is located at `./configs/feature_extraction_configs.yml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH_TO_MVTS: 'data/petdataset_01/'\n",
      "PATH_TO_EXTRACTED_FEATURES: 'data/extracted_features/'\n",
      "META_DATA_TAGS: ['id', 'lab', 'st', 'et']\n",
      "MVTS_PARAMETERS:\n",
      "  - 'TOTUSJH'\n",
      "  - 'TOTBSQ'\n",
      "  - 'TOTPOT'\n",
      "  - 'TOTUSJZ'\n",
      "  - 'ABSNJZH'\n",
      "  - 'SAVNCPP'\n",
      "  - 'USFLUX'\n",
      "  - 'TOTFZ'\n",
      "  - 'MEANPOT'\n",
      "  - 'EPSZ'\n",
      "  - 'MEANSHR'\n",
      "  - 'SHRGT45'\n",
      "  - 'MEANGAM'\n",
      "  - 'MEANGBT'\n",
      "  - 'MEANGBZ'\n",
      "  - 'MEANGBH'\n",
      "  - 'MEANJZH'\n",
      "  - 'TOTFY'\n",
      "  - 'MEANJZD'\n",
      "  - 'MEANALP'\n",
      "  - 'TOTFX'\n",
      "  - 'EPSY'\n",
      "  - 'EPSX'\n",
      "  - 'R_VALUE'\n",
      "STATISTICAL_FEATURES:\n",
      "  - 'get_min'\n",
      "  - 'get_max'\n",
      "  - 'get_median'\n",
      "  - 'get_mean'\n",
      "  - 'get_stddev'\n",
      "  - 'get_var'\n",
      "  - 'get_skewness'\n",
      "  - 'get_kurtosis'\n",
      "  - 'get_no_local_maxima'\n",
      "  - 'get_no_local_minima'\n",
      "  - 'get_no_local_extrema'\n",
      "  - 'get_no_zero_crossings'\n",
      "  - 'get_mean_local_maxima_value'\n",
      "  - 'get_mean_local_minima_value'\n",
      "  - 'get_no_mean_local_maxima_upsurges'\n",
      "  - 'get_no_mean_local_minima_downslides'\n",
      "  - 'get_difference_of_mins'\n",
      "  - 'get_difference_of_maxs'\n",
      "  - 'get_difference_of_means'\n",
      "  - 'get_difference_of_stds'\n",
      "  - 'get_difference_of_vars'\n",
      "  - 'get_difference_of_medians'\n",
      "  - 'get_dderivative_mean'\n",
      "  - 'get_gderivative_mean'\n",
      "  - 'get_dderivative_stddev'\n",
      "  - 'get_gderivative_stddev'\n",
      "  - 'get_dderivative_skewness'\n",
      "  - 'get_gderivative_skewness'\n",
      "  - 'get_dderivative_kurtosis'\n",
      "  - 'get_gderivative_kurtosis'\n",
      "  - 'get_linear_weighted_average'\n",
      "  - 'get_quadratic_weighted_average'\n",
      "  - 'get_average_absolute_change'\n",
      "  - 'get_average_absolute_derivative_change'\n",
      "  - 'get_positive_fraction'\n",
      "  - 'get_negative_fraction'\n",
      "  - 'get_last_value'\n",
      "  - 'get_sum_of_last_K'\n",
      "  - 'get_mean_last_K'\n",
      "  - 'get_slope_of_longest_mono_increase'\n",
      "  - 'get_slope_of_longest_mono_decrease'\n",
      "  - 'get_avg_mono_increase_slope'\n",
      "  - 'get_avg_mono_decrease_slope'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_config = './configs/feature_extraction_configs.yml'\n",
    "with open(path_to_config, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the break-down of the pieces:\n",
    " - `PATH_to_MVTS`: relative path to where the mvts data is stored in.\n",
    " - `PATH_TO_EXTRACTED`: relative path to where the extracted features is/will be stored in.\n",
    " - `META_DATA_TAGS`: a list of strings present in mvts file-names with specific meanings. See the README.md file for more details.\n",
    " - `MVTS_PARAMETERS`: an enumerated list of the parameter names (column names) in the mvts. Comment out those that are not needed using `#` symbol.\n",
    " - `STATISTICAL_FEATURES`: an enumerated list of the methods available through this package. This example has all features. Comment out those that are not needed using `#` symbol.\n",
    " \n",
    " In the following cells, you will see how this can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Raw Data (MVTS Data Analysis)\n",
    "\n",
    "- #### How many files? How large of a dataset?\n",
    "\n",
    "Using `mvts_data_analysis` we can get an idea of the dataset we are going to work on. We start with creating an instance of a `MVTSDataAnalysis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Directory:\t\t\t/home/azim/CODES/PyWorkspace/mvtsdata_toolkit/data/petdataset_01/\n",
      "Total no. of files:\t2698\n",
      "Total size:\t\t\t102M\n",
      "Total average:\t\t38K\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from data_analysis.mvts_data_analysis import MVTSDataAnalysis\n",
    "path_to_config = './configs/feature_extraction_configs.yml'\n",
    "mvda = MVTSDataAnalysis(path_to_config)\n",
    "mvda.print_stat_of_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Get a summary Stats of the data.\n",
    "\n",
    "Let's now get some statistics from the content of the files. To speed up the demo, we analyze only 3 parameters (namely `TOTUSJH`, `TOTBSQ`, and `TOTPOT`), and only the first 50 mvts files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter-Name</th>\n",
       "      <th>Val-Count</th>\n",
       "      <th>Null-Count</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>25th</th>\n",
       "      <th>50th</th>\n",
       "      <th>75th</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOTUSJH</td>\n",
       "      <td>2989</td>\n",
       "      <td>11</td>\n",
       "      <td>4.418819e+02</td>\n",
       "      <td>3.494185e+00</td>\n",
       "      <td>3.367524e+01</td>\n",
       "      <td>8.256577e+01</td>\n",
       "      <td>5.776202e+02</td>\n",
       "      <td>3.162777e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOTBSQ</td>\n",
       "      <td>2989</td>\n",
       "      <td>11</td>\n",
       "      <td>5.641615e+09</td>\n",
       "      <td>1.983268e+07</td>\n",
       "      <td>2.550211e+08</td>\n",
       "      <td>7.174134e+08</td>\n",
       "      <td>7.636239e+09</td>\n",
       "      <td>3.848284e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOTPOT</td>\n",
       "      <td>2989</td>\n",
       "      <td>11</td>\n",
       "      <td>8.022880e+22</td>\n",
       "      <td>1.205181e+20</td>\n",
       "      <td>1.873315e+21</td>\n",
       "      <td>5.280204e+21</td>\n",
       "      <td>6.054911e+22</td>\n",
       "      <td>7.108347e+23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Parameter-Name Val-Count Null-Count          mean           min  \\\n",
       "0        TOTUSJH      2989         11  4.418819e+02  3.494185e+00   \n",
       "1         TOTBSQ      2989         11  5.641615e+09  1.983268e+07   \n",
       "2         TOTPOT      2989         11  8.022880e+22  1.205181e+20   \n",
       "\n",
       "           25th          50th          75th           max  \n",
       "0  3.367524e+01  8.256577e+01  5.776202e+02  3.162777e+03  \n",
       "1  2.550211e+08  7.174134e+08  7.636239e+09  3.848284e+10  \n",
       "2  1.873315e+21  5.280204e+21  6.054911e+22  7.108347e+23  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = ['TOTUSJH', 'TOTBSQ', 'TOTPOT']\n",
    "n = 50\n",
    "mvda.compute_summary(params_name=params, first_k=n)\n",
    "mvda.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which says the length of the time series, across the 50 mvts files is 3000, including 11 `NA/NAN` values. In addition, `mean`, `min`, `max`, and three quantiles are calculated for each time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - #### You have a LARGE dataset?\n",
    " A parallel version of this function is also provided to help process much larger datasets efficiently. Below, we use 4 processes to do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "mvda.compute_summary_in_parallel(n_jobs=4, first_k=50, verbose=False,\n",
    "                                     params_name=['TOTUSJH', 'TOTBSQ', 'TOTPOT'])\n",
    "mvda.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The results of the parallel and sequential versions of `mvts_data_analysis` are not exactly identical. This discrepency is due to the fact that in the parallel version, the program is designed to avoid loading the entire dataset into memory so that it is not confined to any particular data size. Therefore, it relies on some statistical estimators to approximate the percentiles with some acceptable errors. The error significantly decreases as the number of mvts files increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "- #### What statistical features are available?\n",
    "\n",
    "Now that we have an idea about our raw data, let's extract some features from the data. A list of ~50 statistical features are implemented in `feature_collection`. Let's take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import features.feature_collection as fc\n",
    "help(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### How to extract these features from the data?\n",
    "\n",
    "Time to extract a set of these features from the dataset we downloaded. Let's extract 3 simple statistical features, namely `min`, `max`, and `median`, from 3 parameters, such as `TOTUSJH`, `TOTBSQ`, and `TOTPOT`. Again, to speed up the process in this demo, we only process the first 50 mvts files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from features.feature_extractor import FeatureExtractor\n",
    "\n",
    "fe = FeatureExtractor(path_to_config)\n",
    "fe.do_extraction(features_name=['get_min', 'get_max', 'get_median'],\n",
    "                 params_name=['TOTUSJH', 'TOTBSQ', 'TOTPOT'], first_k=50)\n",
    "fe.df_all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... where each row corresponds to one mvts file, and the first 4 columns represent the extracted information from the file names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    " - #### You have a LARGE dataset?\n",
    " No worries. Using the parallel implementation of feature extraction, the process can be significantly sped up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fe.do_extraction_in_parallel(n_jobs=4,\n",
    "                             features_name=['get_min', 'get_max', 'get_median'],\n",
    "                             params_name=['TOTUSJH', 'TOTBSQ', 'TOTPOT'], first_k=50)\n",
    "fe.df_all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracted Features Analysis\n",
    "\n",
    "- #### A quick look over the results?\n",
    "\n",
    "The extracted features can be easily summarized using descriptive statistics such as `meam`, `std`, `min`, `max`, and first, second and third quartiles. In addition, any missing value can also be spotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data_analysis.extracted_features_analysis import ExtractedFeaturesAnalysis\n",
    "\n",
    "efa = ExtractedFeaturesAnalysis(fe.df_all_features, exclude=['id'])\n",
    "efa.compute_summary()\n",
    "efa.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which gives a summary statistics over every extracted feature. For instance, in row `0`, the changes of the minimum values of the parameter `TUOTUSJH`, across 50 mvts files, is described in terms of `mean`, `std`, etc. This also indicates that no `NA/NAN` or missing value was generated in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "\n",
    "The extracted features can then be normalized using four different methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from normalizing import normalizer\n",
    "\n",
    "df_norm = normalizer.zero_one_normalize(df=fe.df_all_features, excluded_colnames=['id'])\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The method argument `excluded_colnames` was used to keep the column `id` intact in the normalization process. Moreover, any other column with non-numeric values were preserved in the output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
